{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTS\n",
    "train_data_path = \"./Training\"\n",
    "test_data_path = \"./Testing\"\n",
    "data_path = \"./Data\"\n",
    "\n",
    "# 128 FOR FASTEST TRAINING/TESTING\n",
    "# 256 FOR FASTISH TRAINING/TESTING\n",
    "# 512 FOR FULL TRAINING/TESTING, VERY SLOW\n",
    "\n",
    "IMG_SIZE = (128, 128) \n",
    "# IMG_SIZE = (256, 256) \n",
    "# IMG_SIZE = (512, 512)\n",
    "\n",
    "classes = ['notumor','pituitary',  'meningioma', 'glioma']\n",
    "image_dict = {} \n",
    "\n",
    "rs = 1337 # leet random state\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE TO ARRAY HELPER FUNCTION\n",
    "def image_to_array(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Convert to grayscale\n",
    "    img = cv2.resize(img, IMG_SIZE)  # Resize to consistent size\n",
    "    return img.flatten()  # Flatten to 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE DUPLICATES FUNCTION\n",
    "def remove_duplicates(data_path):\n",
    "    duplicates = []\n",
    "\n",
    "    for category in classes:\n",
    "        print(\"REMOVING DUPLICATES IN CATEGORY: \", category)\n",
    "        class_path = os.path.join(data_path, category)\n",
    "        if os.path.isdir(class_path):\n",
    "            for img_name in os.listdir(class_path):\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "                img_array = tuple(image_to_array(img_path))  # Convert to immutable tuple\n",
    "                \n",
    "                # Check if image already exists in dictionary\n",
    "                if img_array in image_dict:\n",
    "                    duplicates.append(img_path)\n",
    "                else:\n",
    "                    image_dict[img_array] = img_path  # Store unique image\n",
    "\n",
    "    print(f\"Found {len(duplicates)} duplicate images.\")\n",
    "\n",
    "    # Optionally delete duplicates\n",
    "    for img in duplicates:\n",
    "        os.remove(img)\n",
    "\n",
    "    print(\"Duplicate images removed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only needs to run once, comment out after running to speed things up\n",
    "\n",
    "# remove_duplicates(train_data_path)\n",
    "# remove_duplicates(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE FUNCTIONS\n",
    "def copy_file(src, dst):\n",
    "    with open(src, 'rb') as fsrc:\n",
    "        data = fsrc.read()\n",
    "    with open(dst, 'wb') as fdst:\n",
    "        fdst.write(data)\n",
    "\n",
    "def merge_images(training_dir, testing_dir, output_dir=\"Data\"):\n",
    "    print(\"MERGE STARTING\")\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Get the set of categories from both training and testing directories\n",
    "    training_categories = {d for d in os.listdir(training_dir)\n",
    "                           if os.path.isdir(os.path.join(training_dir, d))}\n",
    "    testing_categories = {d for d in os.listdir(testing_dir)\n",
    "                          if os.path.isdir(os.path.join(testing_dir, d))}\n",
    "    categories = training_categories.union(testing_categories)\n",
    "    \n",
    "    for category in categories:\n",
    "        # Create subfolder in the output directory for this category\n",
    "        category_output_path = os.path.join(output_dir, category)\n",
    "        if not os.path.exists(category_output_path):\n",
    "            os.makedirs(category_output_path)\n",
    "        \n",
    "        # Define paths for training and testing category folders\n",
    "        paths = []\n",
    "        train_cat_path = os.path.join(training_dir, category)\n",
    "        if os.path.exists(train_cat_path):\n",
    "            paths.append(train_cat_path)\n",
    "        \n",
    "        test_cat_path = os.path.join(testing_dir, category)\n",
    "        if os.path.exists(test_cat_path):\n",
    "            paths.append(test_cat_path)\n",
    "        \n",
    "        # Copy JPEG images from each found category folder\n",
    "        for path in paths:\n",
    "            for filename in os.listdir(path):\n",
    "                if filename.lower().endswith(('.jpg', '.jpeg')):\n",
    "                    src = os.path.join(path, filename)\n",
    "                    dst = os.path.join(category_output_path, filename)\n",
    "                    if os.path.exists(dst):\n",
    "                        continue\n",
    "                    copy_file(src, dst)\n",
    "    print(\"MERGE FINISHED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_images(train_data_path, test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "def load_data(data_path):\n",
    "    X = []\n",
    "    y = []\n",
    "    for category in classes:\n",
    "        class_path = os.path.join(data_path, category)\n",
    "        print(f\"LOADING CLASS: {category}\")\n",
    "        if os.path.isdir(class_path):\n",
    "            for img_name in os.listdir(class_path):\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "                img = image_to_array(img_path)\n",
    "                X.append(img)\n",
    "                y.append(category)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    print(\"LOADED ALL IMAGES\")\n",
    "    return X, y\n",
    "\n",
    "def encode_labels(y):\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    return y\n",
    "\n",
    "def decode_labels(y_encoded):\n",
    "    original_labels = label_encoder.inverse_transform(y_encoded)\n",
    "    return original_labels\n",
    "\n",
    "def replace_nan(data):\n",
    "    if np.isnan(data).sum() > 0:\n",
    "        data = np.nan_to_num(data)  # Replace NaN with 0\n",
    "    return data  # Ensure data is returned in all cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA - SET GLOBAL - NORMALIZE AND ENCODE LABELS\n",
    "GLOBAL_X, GLOBAL_y = load_data(data_path)\n",
    "\n",
    "#Replace NAN\n",
    "GLOBAL_X = replace_nan(GLOBAL_X)\n",
    "\n",
    "#Encode Labels\n",
    "print(\"ENCODING Y\")\n",
    "GLOBAL_y = encode_labels(GLOBAL_y)\n",
    "\n",
    "# Normalize pixel values\n",
    "print(\"NORMALIZING X\")\n",
    "GLOBAL_X = GLOBAL_X / 255.0  # Scale pixel values between 0 and 1\n",
    "\n",
    "print(\"TRAIN TEST SPLIT\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(GLOBAL_X, GLOBAL_y, test_size=0.2, random_state=rs, stratify=GLOBAL_y)\n",
    "\n",
    "print(\"TRAINING X, y lengths: \", len(X_train), \" -- \", len(y_train))\n",
    "print(\"TEST X, y lengths: \", len(X_test),\" -- \", len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- EDA ---------------\n",
    "#=== 1 === BASIC DATA SUMMARY\n",
    "print(f\"Total Images: {GLOBAL_X.shape[0]}\")\n",
    "\n",
    "# Count images per class\n",
    "unique, counts = np.unique(GLOBAL_y, return_counts=True)\n",
    "class_counts = dict(zip(unique, counts))\n",
    "\n",
    "# Create a mapping from encoded values to class names using label_encoder\n",
    "label_mapping = {i: label for i, label in enumerate(label_encoder.classes_)}\n",
    "\n",
    "# Sort the keys for consistent ordering\n",
    "sorted_keys = sorted(class_counts.keys())\n",
    "\n",
    "# Print the class distribution using the consistent mapping\n",
    "print(\"\\nClass Distribution:\")\n",
    "for key in sorted_keys:\n",
    "    print(f\"{label_mapping[key]}: {class_counts[key]}\")\n",
    "\n",
    "# Prepare data for plotting\n",
    "class_names = [label_mapping[k] for k in sorted_keys]\n",
    "class_values = [class_counts[k] for k in sorted_keys]\n",
    "\n",
    "# Plot the class distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(class_names, class_values, color=\"skyblue\")\n",
    "plt.xlabel(\"Tumor Type\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.title(\"Class Distribution of MRI Dataset\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPEC ----- HEATMAPS -------------------\n",
    "def load_and_preprocess_images(class_name):\n",
    "    \"\"\"Loads images from a class directory, converts to grayscale, resizes, and normalizes.\"\"\"\n",
    "    class_dir = os.path.join(data_path, class_name)\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    for filename in os.listdir(class_dir):  # Iterate over files\n",
    "        img_path = os.path.join(class_dir, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Read as grayscale\n",
    "        if img is not None:\n",
    "\n",
    "            img = cv2.resize(img, IMG_SIZE) \n",
    "            images.append(img)\n",
    "    \n",
    "    if images:\n",
    "        return np.array(images, dtype=np.float32)  # Convert to float for normalization\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Compute average images for each class\n",
    "average_images = {}\n",
    "for class_name in classes:\n",
    "    images = load_and_preprocess_images(class_name)\n",
    "    if images is not None:\n",
    "        avg_img = np.mean(images, axis=0)\n",
    "        \n",
    "        # Normalize to range [0, 1] for better contrast\n",
    "        avg_img = (avg_img - np.min(avg_img)) / (np.max(avg_img) - np.min(avg_img))\n",
    "        \n",
    "        average_images[class_name] = avg_img\n",
    "\n",
    "# Plot heatmaps with controlled intensity\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, class_name in enumerate(classes):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    if class_name in average_images:\n",
    "        plt.imshow(average_images[class_name], cmap=\"hot\", vmin=.8, vmax=1)  # Adjust vmax to reduce brightness\n",
    "        plt.colorbar()\n",
    "        plt.title(f\"Heatmap: {class_name}\")\n",
    "        plt.axis(\"off\")\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, \"No Data\", ha='center', va='center', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=== 3 === PRINCIPAL COMPONENT ANALYSIS\n",
    "X_sample = X_train\n",
    "y_sample = y_train\n",
    "\n",
    "# Flatten images\n",
    "X_flattened = X_sample.reshape(X_sample.shape[0], -1)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_flattened)\n",
    "\n",
    "unique_classes = list(np.unique(GLOBAL_y)) \n",
    "# Convert class labels to numerical indices for color mapping\n",
    "class_indices = [unique_classes.index(cls) for cls in y_sample]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=class_indices, cmap=\"jet\", alpha=0.2)\n",
    "\n",
    "# Create a colorbar and relabel it with class names\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label(\"Class Label\")\n",
    "\n",
    "# Set custom tick labels on the colorbar\n",
    "cbar.set_ticks(range(len(unique_classes)))  # Set ticks to match class indices\n",
    "cbar.set_ticklabels(decode_labels(unique_classes))  # Replace numeric labels with class names\n",
    "\n",
    "plt.title(\"PCA Visualization of MRI Images\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == REPORT FUNCTIONS === \n",
    "classification_reports = {}\n",
    "\n",
    "def add_classification_report(title, confusion_matrix, accuracy_score, classification_report, y_probs = [], model_classes = []):\n",
    "    report = {\n",
    "        \"title\": title,\n",
    "        \"confusion_matrix\":confusion_matrix,\n",
    "        \"accuracy_score\":accuracy_score,\n",
    "        \"classification_report\":classification_report,\n",
    "        \"y_probs\": y_probs,\n",
    "        \"model_classes\": model_classes\n",
    "    }\n",
    "    classification_reports[title] = report\n",
    "\n",
    "def display_classification_reports(show_heatmap = False):\n",
    "    for title, report in classification_reports.items():\n",
    "        accuracy_score = report.get(\"accuracy_score\")\n",
    "        print(f\"{title} - {round(accuracy_score, 3)}\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "    for title, report in classification_reports.items():\n",
    "        confusion_matrix = report.get(\"confusion_matrix\")\n",
    "        accuracy_score = report.get(\"accuracy_score\")\n",
    "        classification_report = report.get(\"classification_report\")\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(f\"{title.upper():^50}\")  # Centered title\n",
    "        print(\"=\" * 50 + \"\\n\")\n",
    "        print(\"Accuracy: \", accuracy_score)\n",
    "        print(classification_report)\n",
    "\n",
    "        if show_heatmap:\n",
    "            sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "            plt.xlabel(\"Predicted\")\n",
    "            plt.ylabel(\"Actual\")\n",
    "            plt.title(\"Confusion Matrix\")\n",
    "            plt.show()\n",
    "        \n",
    "        y_probs = report.get(\"y_probs\")\n",
    "        model_classes = report.get(\"model_classes\")\n",
    "        display_roc_auc(y_probs, model_classes)\n",
    "\n",
    "def get_highest_accuracy():\n",
    "    highest_acc = 0\n",
    "    highest_title = \"\"\n",
    "    for title, report in classification_reports.items():\n",
    "        accuracy_score = report.get(\"accuracy_score\")\n",
    "        if accuracy_score > highest_acc:\n",
    "            highest_acc = accuracy_score\n",
    "            highest_title = title\n",
    "    print(f\"HIGHEST ACCURACY: {highest_title} - {round(highest_acc, 3)}\")\n",
    "\n",
    "\n",
    "def display_roc_auc(y_probs, model_classes):\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Loop through each numeric class from the model\n",
    "    for i, numeric_label in enumerate(model_classes):\n",
    "        real_label = classes[i]\n",
    "        \n",
    "        # Compute ROC curve treating the current class as positive (one-vs-rest)\n",
    "        fpr, tpr, _ = roc_curve(y_test == numeric_label, y_probs[:, i])\n",
    "        auc_score = roc_auc_score(y_test == numeric_label, y_probs[:, i])\n",
    "        \n",
    "        # Plot ROC curve using the real label in the legend\n",
    "        plt.plot(fpr, tpr, label=f\"{real_label} (AUC = {auc_score:.4f})\")\n",
    "\n",
    "    # Plot the diagonal line for reference (random classifier)\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Random Classifier\")\n",
    "\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Multi-Class ROC Curve (One-vs-Rest)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features (important for SVM and KNN)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOGISTIC REGRESSION ===\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_probs = model.predict_proba(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cr = classification_report(y_test, y_pred, target_names=classes)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "add_classification_report(\"LogisticRegression\", cm, accuracy, cr, y_probs, model.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RANDOM FOREST - 1 - FIND n_estimators === 13min\n",
    "# Can comment this out after a good n_estimator is found\n",
    "# Note: Platues around 60\n",
    "n_values = np.arange(10, 90, 10)\n",
    "oob_errors = []\n",
    "lowest_n_estimator = 1000\n",
    "lowest_err = 1\n",
    "for n in n_values:\n",
    "    print(\"n \", n)\n",
    "    rf = RandomForestClassifier(n_estimators=n, oob_score=True, random_state=42, bootstrap=True)\n",
    "    rf.fit(X_train, y_train)\n",
    "    err = 1 - rf.oob_score_\n",
    "    if err < lowest_err:\n",
    "        lowest_err = err\n",
    "        lowest_n_estimator = n\n",
    "    oob_errors.append(err)\n",
    "\n",
    "print(\"Lowest n estimator: \", n)\n",
    "print(\"Lowest oob err: \", lowest_err)\n",
    "\n",
    "plt.plot(n_values, oob_errors, marker='o')\n",
    "plt.xlabel('Number of Trees (n_estimators)')\n",
    "plt.ylabel('OOB Error Rate')\n",
    "plt.title('OOB Error vs. n_estimators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RANDOM FOREST - 2 - MODEL=== \n",
    "rf_model = RandomForestClassifier(n_estimators=50, random_state=rs)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "rf_pred = rf_model.predict(X_test_scaled)\n",
    "y_probs = rf_model.predict_proba(X_test_scaled)\n",
    "\n",
    "acc = accuracy_score(y_test, rf_pred)\n",
    "cr = classification_report(y_test, rf_pred, target_names=classes)\n",
    "cm = confusion_matrix(y_test, rf_pred)\n",
    "\n",
    "add_classification_report(\"RANDOM FOREST\", cm, acc, cr, y_probs, rf_model.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Consts\n",
    "slice_num = 1000\n",
    "C_values = np.logspace(-1, 1, 10)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "use_slice = False\n",
    "\n",
    "if use_slice:\n",
    "    svm_X_train_scaled = X_train_scaled[:slice_num].copy()\n",
    "    svm_X_test_scaled = X_test_scaled[:slice_num].copy()\n",
    "    svm_y_train = y_train[:slice_num].copy()\n",
    "    svm_y_test = y_test[:slice_num].copy()\n",
    "else:\n",
    "    svm_X_train_scaled = X_train_scaled.copy()\n",
    "    svm_X_test_scaled = X_test_scaled.copy()\n",
    "    svm_y_train = y_train.copy()\n",
    "    svm_y_test = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SUPPORT VECTOR MACHINE ===\n",
    "# 1 - FIND HYPERPARAMETER C\n",
    "for C in C_values:\n",
    "    # print(C)\n",
    "    svm = SVC(kernel='rbf', C=C, random_state=rs)\n",
    "    svm.fit(svm_X_train_scaled, svm_y_train)\n",
    "    train_scores.append(accuracy_score(svm_y_train, svm.predict(svm_X_train_scaled)))\n",
    "    test_scores.append(accuracy_score(svm_y_test, svm.predict(svm_X_test_scaled)))\n",
    "    \n",
    "\n",
    "plt.plot(C_values, train_scores, label='Train Accuracy', marker='o')\n",
    "plt.plot(C_values, test_scores, label='Test Accuracy', marker='s')\n",
    "plt.xlabel(\"C Value\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"SVM Performance vs. C\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SVM - MODEL ===\n",
    "#Training on the full dataset takes a long time\n",
    "svm_model = SVC(kernel='rbf', C=4, random_state=rs, probability=True)  # RBF kernel is commonly used\n",
    "svm_model.fit(svm_X_train_scaled, svm_y_train)\n",
    "svm_pred = svm_model.predict(svm_X_test_scaled)\n",
    "y_probs = svm_model.predict_proba(X_test_scaled)\n",
    "\n",
    "cm = confusion_matrix(svm_y_test, svm_pred)\n",
    "acc = accuracy_score(svm_y_test, svm_pred)\n",
    "cr = classification_report(svm_y_test, svm_pred, target_names=classes)\n",
    "\n",
    "add_classification_report(\"SUPPORT VECTOR MACHINE\", cm, acc, cr, y_probs, svm_model.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN - FIND BEST K\n",
    "\n",
    "# Range of k values to test\n",
    "k_values = range(1, 10)  \n",
    "cv_scores = []\n",
    "\n",
    "# Perform cross-validation for each k\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train_scaled, y_train, cv=5, scoring='accuracy')  # 5-fold CV\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "# Plot accuracy vs. k values\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(k_values, cv_scores, marker='o', linestyle='dashed')\n",
    "plt.xlabel(\"Number of Neighbors (k)\")\n",
    "plt.ylabel(\"Cross-Validated Accuracy\")\n",
    "plt.title(\"Choosing the Best k for KNN\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Finding the best k (elbow point)\n",
    "best_k = k_values[np.argmax(cv_scores)]\n",
    "print(f\"Best k based on cross-validation: {best_k}, Accuracy: {max(cv_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === KNN === \n",
    "knn_best = KNeighborsClassifier(n_neighbors=2)\n",
    "knn_best.fit(X_train_scaled, y_train)\n",
    "knn_pred = knn_best.predict(X_test_scaled)\n",
    "y_probs = knn_best.predict_proba(X_test_scaled)\n",
    "\n",
    "cm = confusion_matrix(y_test, knn_pred)\n",
    "acc = accuracy_score(y_test, knn_pred)\n",
    "cr = classification_report(y_test, knn_pred, target_names=classes)\n",
    "\n",
    "add_classification_report(\"K-NN\", cm, acc, cr, y_probs, knn_best.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_highest_accuracy()\n",
    "\n",
    "display_classification_reports(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
